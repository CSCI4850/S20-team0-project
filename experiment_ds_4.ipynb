{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.hgg_utils as hu\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tqdm.notebook import tqdm \n",
    "from model import unet\n",
    "from utils.dice import dice_loss as dice\n",
    "from utils.dice import dice_coef as dice_coef\n",
    "from sklearn.utils import shuffle\n",
    "from IPython import display\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#policy = mixed_precision.Policy(\"float32\") \n",
    "policy = mixed_precision.Policy(\"mixed_float16\")\n",
    "mixed_precision.set_policy(policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_load = 5\n",
    "n_slices = 155\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The val that varies between experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare to load in some input data and masks and remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patients = hu.get_each_normalized_hgg_folder()\n",
    "patients = hu.remove_outliers(patients)\n",
    "\n",
    "masks = hu.get_each_hgg_folder()\n",
    "masks = hu.remove_outliers(masks)\n",
    "\n",
    "patients, masks = shuffle(patients, masks, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_ratio = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_start = 0\n",
    "train_stop = int(np.round(train_data_ratio * len(patients)))\n",
    "print(train_start)\n",
    "train_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_start = train_stop\n",
    "test_stop = len(patients)\n",
    "print(test_start)\n",
    "test_stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save paths for train "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = patients[:test_start]\n",
    "train_masks = masks[:test_start]\n",
    "\n",
    "fname_train_data = \"ds_\"+str(ds)+\"_train_data.pkl\"\n",
    "fname_train_masks = \"ds_\"+str(ds)+\"_train_masks.pkl\"\n",
    "\n",
    "with open(fname_train_data, 'wb') as file_pi:\n",
    "    pickle.dump(train_data, file_pi)\n",
    "    \n",
    "with open(fname_train_masks, 'wb') as file_pi:\n",
    "    pickle.dump(train_masks, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the paths for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = patients[test_start:]\n",
    "test_masks = masks[test_start:]\n",
    "\n",
    "fname_test_data = \"ds_\"+str(ds)+\"_test_data.pkl\"\n",
    "fname_test_masks = \"ds_\"+str(ds)+\"_test_masks.pkl\"\n",
    "\n",
    "with open(fname_test_data, 'wb') as file_pi:\n",
    "    pickle.dump(test_data, file_pi)\n",
    "    \n",
    "with open(fname_test_masks, 'wb') as file_pi:\n",
    "    pickle.dump(test_masks, file_pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preallocate arrays to hold data & masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_data = np.ones([ num_to_load*155, 240, 240, 4])\n",
    "some_masks = np.ones([ num_to_load*155, 240, 240, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_n_brains(data, start, stop, paths, end):\n",
    "\n",
    "    data_idx = 0\n",
    "    num_slices = 155\n",
    "    brains_seen = 0\n",
    "    \n",
    "    #for multimodal_tensor in tqdm(range(start, stop)):\n",
    "    for multimodal_tensor in range(start, stop):\n",
    "\n",
    "        if multimodal_tensor != end:\n",
    "            four_channel_scan = hu.reshape_tensor_with_slices_first(\n",
    "                                    hu.get_a_multimodal_tensor( \n",
    "                                                paths[multimodal_tensor] \n",
    "                                    )[data_idx]\n",
    "            )\n",
    "            #print(paths[multimodal_tensor])\n",
    "\n",
    "\n",
    "            for slic in range(num_slices):\n",
    "                data[slic+(num_slices*brains_seen),:,:,:] = four_channel_scan[slic,:,:,:]\n",
    "\n",
    "            brains_seen += 1\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "    #print(multimodal_tensor)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_n_masks(data, start, stop, paths, end):\n",
    "\n",
    "    data_idx = 0\n",
    "    num_slices = 155\n",
    "    brains_seen = 0\n",
    "\n",
    "    for mask_idx in range(start, stop):\n",
    "        if mask_idx != end:\n",
    "\n",
    "            mask =  hu.reshape_tensor_with_slices_first(\n",
    "                                    hu.convert_mask_to_binary_mask(\n",
    "                                         hu.get_a_mask_tensor( paths[mask_idx] )\n",
    "\n",
    "                                   )\n",
    "            )\n",
    "            #print(paths[mask_idx])\n",
    "\n",
    "\n",
    "            for slic in range(num_slices):\n",
    "                data[slic+(num_slices*brains_seen),:,:,:] = mask[slic,:,:,:]\n",
    "\n",
    "            brains_seen += 1\n",
    "        else:\n",
    "            break\n",
    "            \n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = 39\n",
    "\n",
    "beg = 0\n",
    "end = num_to_load*155\n",
    "truncated = 155*(train_stop - ( (chunks-1) * num_to_load  ) )\n",
    "\n",
    "#truncated\n",
    "#155*(train_stop - ( (chunks-1) * num_to_load  ) )\n",
    "\n",
    "my_opt = tf.keras.optimizers.Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "for run in tqdm(range(5)):\n",
    "    \n",
    "    print(\"********************\")\n",
    "    print(\"Run:\", run)\n",
    "    \n",
    "    model = unet( input_size=(240,240,4), ds=ds )\n",
    "    # Save architecture\n",
    "    model_json_name = \"unet_ds_{}.json\".format(ds)\n",
    "    with open(model_json_name, \"w\") as json_file:\n",
    "        json_file.write(model.to_json())\n",
    "        \n",
    "    model.compile(optimizer=my_opt, loss=dice, metrics=[dice_coef])\n",
    "    \n",
    "    run_history = []\n",
    "\n",
    "    for epoch in tqdm(range(20)):\n",
    "        \n",
    "        epoch_history = []\n",
    "        \n",
    "        for i in range(chunks):\n",
    "            print(\"Loading chunk of data...\")\n",
    "            some_data = load_n_brains(some_data,  (num_to_load*i), (num_to_load*i)+num_to_load, patients, train_stop).astype(np.float32)\n",
    "            some_masks = load_n_masks(some_masks, (num_to_load*i), (num_to_load*i)+num_to_load, masks, train_stop).astype(np.float32)\n",
    "\n",
    "            some_data, some_masks = shuffle(some_data, some_masks, random_state=1)\n",
    "\n",
    "            if num_to_load*i+num_to_load <= train_stop:\n",
    "                history = model.fit(some_data[beg:end,...], some_masks[beg:end,...], validation_split=0.2, epochs=1, batch_size=32)\n",
    "\n",
    "            else:\n",
    "                history = model.fit(some_data[beg:truncated,...], some_masks[beg:truncated,...], validation_split=0.2, epochs=1, batch_size=32)\n",
    "\n",
    "\n",
    "            epoch_history.append(history.history)\n",
    "        print(\"Epoch\", epoch, \"completed\")\n",
    "        print(\"Elapsed time:\", (time.time() - start_time)/60.0, \"minutes\" )\n",
    "        run_history.append(epoch_history)\n",
    "    \n",
    "    print()\n",
    "    print(\"Saving run\", run, \"loss etc.\")\n",
    "    history_name = \"ds_\"+str(ds)+\"_run_\" + str(run) +\"_histories.pkl\"\n",
    "\n",
    "    with open(history_name, 'wb') as file_pi:\n",
    "        pickle.dump(run_history, file_pi)\n",
    "    \n",
    "    model_weights_name = \"ds_\"+str(ds)+\"_run_\" + str(run) +\"_model_weights.h5\"\n",
    "    \n",
    "    print(\"Saving run\", run, \"model weights as\", model_weights_name)\n",
    "    model.save_weights(model_weights_name)\n",
    "    \n",
    "    del model\n",
    "    \n",
    "print(\"Total time:\", (time.time() - start_time)/60.0, \"minutes\"  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print( run_history[0].history )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
