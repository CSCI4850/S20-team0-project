{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leabra Team Members:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Brian Sharber,\n",
    "Christine Monchecourt,\n",
    "David Woods,\n",
    "Joshua Ortner,\n",
    "Joshua LaFever,\n",
    "Lucas Remedios"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overall Goals:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computer-aided diagnosis (CAD) is an approach that uses software to enhance radiologist interpretations of medical images. The goal of our project is to design a CAD software system to detect the pixel locations of tumors in 2D slices of 3D brain MRIs. To this end, we will train a deep convolutional neural network to perform the desired tumor segmentation. Our model will output a 2D image explicitly showing which pixels in a given 2D brain MRI slice it has predicted to be exhibiting a tumor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Technology:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The heart of our software approach will be a convolutional neural network (CNN) — this will be the tool to enable the segmentation of tumors. CNNs are specialized neural networks that are commonly applied to analyzing images; they use filters to scan an entire image and process its features. For this project, a deep CNN will be utilized for our medical image analysis. The input to the CNN will consist of brain images, in the form of 2D matrices of pixels, which will be processed for tumor segmentation. \n",
    "\n",
    "Our specific deep CNN architecture will be U-net, a popular architecture for this type of complex medical image segmentation task. We will implement our network using the Keras library for the Python programming language. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BraTS Dataset:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the BraTS dataset from the Multimodal Brain Tumor Segmentation challenge. This dataset contains multiple types of brain MRI scans from a variety of sources. The dataset focuses on the visual segmentation of brain tumors as well as the corresponding records of patient survival. Our project will solely deal with the visual segmentation of tumors. The labels in the dataset have been recently checked by board-certified neuroradiologists. The dataset has already been preprocessed to align the brains, even out the resolution, and remove the skulls."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Qualitative Analysis of Model Performance:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To qualitatively evaluate the performance of the model we will perform a visual inspection between select ground truth masks (provided in the dataset), and the predicted masks produced by our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quantitative Analysis of Model Performance:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metric: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the Dice coefficient (Dice score) to measure the segmentation performance of the model. During training we will be looking to maximize the Dice score on the training and validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Metric:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also be using the Dice score to evaluate loss, by subtracting the Dice score from one. During training we will aim to reduce the loss on the training and validation data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test-Validation Split:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To verify the performance of our model, we will be implementing a train-test-validation split. We will partition our dataset into 3 parts, with 60% going toward training, 20% going toward validation, and the last 20% going toward testing. Our neural network will learn its weights through iteratively improving its predictions on data in the training set. During the training phase, to see how well the network will generalize, we will also test it on the validation data (without updating the weights) and record its performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing — Determining Success of the Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throughout the training process we will be collecting data showing model performance and will tweak our model in pursuit of lowering loss and improving its Dice score on the training and validation sets. This performance data will be collected and graphed to determine changes in the loss and Dice score over time. Once the Dice score has plateaued on the training and validation sets, the model’s predicted masks are qualitatively good when visually compared against the ground truth masks, and we have exhausted all reasonable tuning of the model’s parameters, we will test the model on the testing data. If the performance on the testing data is similar to that of the training and validation performance and the predicted masks are visually satisfactory, then we will deem the model successful. \n",
    "\t\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[1] B. H. Menze, A. Jakab, S. Bauer, J. Kalpathy-Cramer, K. Farahani, J. Kirby, et al. \"The Multimodal Brain Tumor Image Segmentation Benchmark (BRATS)\", IEEE Transactions on Medical Imaging 34(10), 1993-2024 (2015) DOI: 10.1109/TMI.2014.2377694"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[2] S. Bakas, H. Akbari, A. Sotiras, M. Bilello, M. Rozycki, J.S. Kirby, et al., \"Advancing The Cancer Genome Atlas glioma MRI collections with expert segmentation labels and radiomic features\", Nature Scientific Data, 4:170117 (2017) DOI: 10.1038/sdata.2017.117"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[3] S. Bakas, M. Reyes, A. Jakab, S. Bauer, M. Rempfler, A. Crimi, et al., \"Identifying the Best Machine Learning Algorithms for Brain Tumor Segmentation, Progression Assessment, and Overall Survival Prediction in the BRATS Challenge\", arXiv preprint arXiv:1811.02629 (2018)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[4] S. Bakas, H. Akbari, A. Sotiras, M. Bilello, M. Rozycki, J. Kirby, et al., \"Segmentation Labels and Radiomic Features for the Pre-operative Scans of the TCGA-GBM collection\", The Cancer Imaging Archive, 2017. DOI: 10.7937/K9/TCIA.2017.KLXWJJ1Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[5] S. Bakas, H. Akbari, A. Sotiras, M. Bilello, M. Rozycki, J. Kirby, et al., \"Segmentation Labels and Radiomic Features for the Pre-operative Scans of the TCGA-LGG collection\", The Cancer Imaging Archive, 2017. DOI: 10.7937/K9/TCIA.2017.GJQ7R0EF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
